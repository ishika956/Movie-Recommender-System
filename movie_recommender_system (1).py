# -*- coding: utf-8 -*-
"""Movie_recommender_system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tIGwPz9KMm3ZZ9X360qIX3c4RpdlaVOe

# Types of recommender system

1. Content based

2. Collaborative filtering

3. Hybrid

# Project Flow

1. Data
2. Preprocessing
3. Model
4. Website
5. Deploy
"""

import numpy as np
import pandas as pd

movies = pd.read_csv('/content/tmdb_5000_movies.csv')
credits = pd.read_csv('/content/tmdb_5000_credits.csv', on_bad_lines='skip')

movies.head()

credits.head()

## Merging the datasets
movies = movies.merge(credits, on = 'title')

movies.head(1)

## Removing columns which are going to use
movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]

movies.head(1)

"""# Preprocessing"""

## to check if there any null column in any row
movies.isnull().sum()

movies.dropna(inplace=True)

## To check if there is duplicate data or not
movies.duplicated().sum()

## Now convert some columns into correct format
movies.iloc[0].genres

## Now from above line we can see the actual format of genres and we have to convert it into  -->  ['Action', 'Adventure', 'Fantasy', 'Science Fiction']
def convert(obj):
  L = []
  for i in ast.literal_eval(obj):
    L.append(i['name'])
  return L

## Now if we run this and call convert function with above row of genre then it will show error the string indices must be integers
## so we will use ast
import ast
# ast.literal_eval()

movies['genres'] = movies['genres'].apply(convert)

movies.head(1)

movies['keywords'] = movies['keywords'].apply(convert)

movies.head(1)

## Now cast will not be same
## In cast we only want first three dictionaries

def convert3(obj):
  L = []
  counter = 0
  for i in ast.literal_eval(obj):
    if counter != 3:
      L.append(i['name'])
      counter += 1
    else:
      break
  return L

movies['cast'] = movies['cast'].apply(convert3)

movies.head(1)

## For crew we only want data for director
def fetch_director(obj):
  L = []
  for i in ast.literal_eval(obj):
    if i['job'] == 'Director':
      L.append(i['name'])
      break
  return L

movies['crew'] = movies['crew'].apply(fetch_director)

movies.head()

## Now convert overview to list of strings
movies['overview'] = movies['overview'].apply(lambda x:x.split())

movies.head(1)

## Now we have to remove space from strings in list of columns
movies['genres'] = movies['genres'].apply(lambda x:[i.replace(" ", "") for i in x])
movies['keywords'] = movies['keywords'].apply(lambda x:[i.replace(" ", "") for i in x])
movies['cast'] = movies['cast'].apply(lambda x:[i.replace(" ", "") for i in x])
movies['crew'] = movies['crew'].apply(lambda x:[i.replace(" ", "") for i in x])

movies.head(1)

## Now concatenate all above 4 columns into one named tag
movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']

movies.head(1)

new_df = movies[['movie_id', 'title', 'tags']]

new_df

## Now convert the list in tags to string
new_df['tags'] = new_df['tags'].apply(lambda x:" ".join(x))

new_df.head(1)

new_df['tags'][0]

## Convert all characters in lower case
new_df['tags'] = new_df['tags'].apply(lambda x:x.lower())

new_df.head(1)

import nltk

from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

def stem(text):
  y = []
  for i in text.split():
    y.append(ps.stem(i))
  return " ".join(y)

new_df['tags'] = new_df['tags'].apply(stem)

"""Now here we convert text to vectors then check which vector is close and the give those vectors as recommendations    -->    so here we use bags of words

Now here waht we do --> we first of all merige all tags and then find the top 5000 frequency words in that and we also use stop words(jinka sentence ki meaning m koi kaam nhi hota)  then map all movies with each highest coming word with number of time it is coming then during prediction we check wether ewhich movie has the highest frequency of that word
"""

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 5000, stop_words = 'english')

vectors = cv.fit_transform(new_df['tags']).toarray()

vectors

vectors[0]

cv.get_feature_names_out()

from sklearn.metrics.pairwise import cosine_similarity

similarity = cosine_similarity(vectors)

similarity

def recommend(movie):
  movie_index = new_df[new_df['title'] == movie].index[0]
  distances = similarity[movie_index]
  movies_list = sorted(list(enumerate(distances)), reverse = True, key = lambda x:x[1])[1:6]

  for i in movies_list:
    print(new_df.iloc[i[0]].title)

"""in the above cell we formed a function recommend function in which we recommend the movies on the basis of cosine similarity that we formed above so what we do in this function is we first find the index of that movie and tehn find it similarity=ies with other movies and sort then in descending order and then we will print the first five movies with highest similarities"""

recommend('Avatar')

import pickle

pickle.dump(new_df,open('movie_list.pkl','wb'))
pickle.dump(similarity,open('similarity.pkl','wb'))

